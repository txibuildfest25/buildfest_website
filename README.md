# **Social Impact BuildFest â€“ EveryLibrary Advocacy Project**  
ðŸ”Š **Enhancing Digital Advocacy Through Multi-Sensory Engagement** âœ¨  

## **Overview**  
Advocacy is most effective when itâ€™s **immersive and accessible**. This project integrates **sentiment analysis, haptic feedback, and text-to-speech** to create a **multi-sensory experience** that enhances memory retention and engagementâ€”especially for individuals with **ADHD, dyslexia, and other neurodiverse conditions**.  

By **targeting multiple senses** (visual, auditory, and tactile), we enable users to better process and recall advocacy messages, making digital content more inclusive and impactful.  

---

## **How It Works**  

âœ… **Sentiment Analysis Engine**  
- Analyzes text **sentence-by-sentence** using a **hybrid NLP model** combining:  
  - **Rule-based approaches** (NLTK lexicons, multi-word expressions)  
  - **Transformer-based emotion classification** (Hugging Face models)  

âœ… **Haptic Feedback Integration**  
- Converts emotional intensity into **haptic signals**, generating **DataFeel JSON commands** that map to different levels of engagement.  

âœ… **Text-to-Speech (TTS) Support**  
- Uses **pyttsx3** to **audibly reinforce** key information, catering to auditory learners.  

âœ… **Customizable Accessibility Features**  
- **Dyslexia-friendly fonts** (OpenDyslexic, Atkinson Hyperlegible)  
- **Adjustable contrast & font sizes**  
- **Multi-file batch processing** for efficiency  

âœ… **Visual Emotion Timeline**  
- Uses **Matplotlib** to create a **dynamic emotion visualization**, providing users with a visual representation of emotional shifts throughout the text.  

---

## **Why It Matters**  
ðŸ§  **More Senses = Better Retention & Recall**  
Research shows that **engaging multiple senses** strengthens memory formation. This tool benefits **everyone**, but especially individuals with:  
- **Dyslexia** (alternative reading methods, enhanced comprehension)  
- **ADHD** (multi-sensory engagement improves focus)  
- **Neurodivergent learners** (customizable settings enhance cognitive processing)  

---

## **Emotion Timeline Visualizations**  
![image](https://github.com/user-attachments/assets/b3e44ade-c3e5-4871-90e5-e0b68bb47d5f)

## **Installation & Usage**  

### **Prerequisites**  
Ensure you have **Python 3.9+** installed along with the required libraries:  
```bash
pip install pyqt6 nltk transformers matplotlib pyttsx3
```

### **Run the Application**  
```bash
python main.py
```
Load a text file, analyze sentiment, and experience the multi-sensory feedback in real-time!  

---

## **Tech Stack & Tools**  
ðŸ›  **Programming Languages:** Python  
ðŸ“š **Libraries & Frameworks:** PyQt6, NLTK, Hugging Face, Matplotlib, Pyttsx3  
ðŸ’¾ **Hardware Integration:** DataFeel SDK  

---

## **Contributing**  
Interested in improving accessibility in digital advocacy? Feel free to **fork the repo, submit PRs, or open issues!** ðŸš€  

ðŸ“© **Questions or Feedback?** Reach out via [LinkedIn](https://linkedin.com/in/paawan-desai) or [GitHub Issues](https://github.com/paawandesai/social-impact-buildfest/issues).  

---

  
